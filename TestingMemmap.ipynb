{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "import json\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os.path\n",
    "import glob\n",
    "import fingerprint\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchGenerator(batch_size, path, num_classes):\n",
    "\n",
    "    batch_start = 0\n",
    "    batch_end = batch_size\n",
    "\n",
    "    with open(path + 'dimensions_X.npy', 'rb') as f:\n",
    "        dimensions_X = pickle.load(f)\n",
    "\n",
    "    with open(path + 'num_examples.npy', 'rb') as f:\n",
    "        num_examples = pickle.load(f)\n",
    "\n",
    "    #this line is just to make the generator infinite, keras needs that\n",
    "    while True:\n",
    "        print('initializing generator')\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < num_examples:\n",
    "            limit = min(batch_end, num_examples)\n",
    "\n",
    "            x_train = []\n",
    "            y_train = []\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                offset_x = int((batch_start + i) * dimensions_X[2] * 32 / 8)\n",
    "                print(offset_x)\n",
    "                offset_y = int((batch_start + i) * num_classes * 32 / 8)\n",
    "                # numpy.memmap.take\n",
    "\n",
    "                x_train.append(np.memmap(path + 'train_data_x.memmap', dtype='float32', mode='r', shape=((dimensions_X[2],)), offset=offset_x))\n",
    "\n",
    "                y_train.append(np.memmap(path + 'train_data_y.memmap', dtype='float32', mode='r', shape=((num_classes,)), offset=offset_y))\n",
    "\n",
    "            # keep dimensions happy\n",
    "            x_train = np.asarray(x_train)\n",
    "            y_train = np.asarray(y_train)\n",
    "\n",
    "            yield (x_train, y_train) #a tuple with two numpy arrays with batch_size samples\n",
    "            batch_start += batch_size\n",
    "            batch_end += batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gen = batchGenerator(1, '/Volumes/Remote_BU/Data/nsynth-train/nsynth-test/', 128)\n",
    "# '/Volumes/Remote_BU/Data/nsynth-train/nsynth-test/'\n",
    "# './data/'\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 = 22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4727808\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "index: 27\n",
      "73\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train = next(gen)\n",
    "print(y_train)\n",
    "x_train = np.reshape(x_train, (256,171))\n",
    "plt.imshow(x_train)\n",
    "maxX = np.count_nonzero(x_train)\n",
    "\n",
    "print('index: ' + str(idx))\n",
    "idx += 1\n",
    "\n",
    "print(maxX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fingerprint(audio, sr):\n",
    "    print = fingerprint.fingerprint(audio, sr,\n",
    "                    wsize=1024,\n",
    "                    wratio=0.5,\n",
    "                    amp_min=10,\n",
    "                    peak_neighborhood=10)\n",
    "    return print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(inpath, example_win, hop, flatten=True):\n",
    "\n",
    "    audio, sr = librosa.load(inpath, res_type='kaiser_fast')\n",
    "    data = generate_fingerprint(audio, sr)\n",
    "\n",
    "    endIdx = hop\n",
    "    startIdx = 0\n",
    "    output_arr = []\n",
    "\n",
    "    while True:\n",
    "        endIdx = startIdx + example_win\n",
    "        if endIdx > data.shape[0]:\n",
    "            break\n",
    "        if flatten:\n",
    "            thisData = data[startIdx:endIdx, :]\n",
    "            thisData = np.reshape(thisData, (thisData.shape[0] * thisData.shape[1]))\n",
    "        else:\n",
    "            thisData = data[startIdx:endIdx, :]\n",
    "\n",
    "        output_arr.append(thisData)\n",
    "        startIdx += hop\n",
    "\n",
    "    output_arr = np.asarray(output_arr)\n",
    "\n",
    "    return output_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveMemmap(X, Y, batch_idx, batch_save):\n",
    "    print('save memmap - input x shape: ' + str(X.shape))\n",
    "    print('save memmap - input y shape: ' + str(Y.shape))\n",
    "\n",
    "    l = list(X.shape)\n",
    "\n",
    "    # offset_x = int((batch_idx * batch_save)*int(l[1])*int(l[2])*32/8)\n",
    "    # offset_y = int((batch_idx * batch_save)*32/8)\n",
    "    # offset_x = int((batch_idx * batch_save)*int(l[0])*int(l[1])*32/8)\n",
    "    offset_x = int((batch_idx * batch_save) * X.shape[0] * X.shape[1] * 32 / 8)\n",
    "    offset_y = int((batch_idx * batch_save) * Y.shape[0] * Y.shape[1] * 32 / 8)\n",
    "\n",
    "    x_file = np.memmap(path + 'train_data_x.memmap', dtype='float32', mode='r+', shape=X.shape, offset=offset_x)\n",
    "    x_file[:] = X\n",
    "    del x_file\n",
    "\n",
    "    y_file = np.memmap(path + 'train_data_y.memmap', dtype='float32', mode='r+', shape=Y.shape, offset=offset_y)\n",
    "    y_file[:] = Y\n",
    "    del y_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path, num_classes, numfiles, batch_save, num_threads, example_win, hop, init_memmap=False):\n",
    "    # batch_save determines the size of the batch saved before a new array is started\n",
    "    json_path = path + 'examples_copy.json'\n",
    "    with open(json_path, 'r') as f:\n",
    "        train = json.load(f)\n",
    "\n",
    "    # get the dimensions of fingerprint using dummy file\n",
    "    sample_print = extract_features('./sample/sample0.wav', example_win, hop)\n",
    "    dimensions = sample_print.shape\n",
    "\n",
    "    examplesPerPrint = dimensions[0]\n",
    "    # expand size of numfiles to number of actual examples per file\n",
    "    numfiles = numfiles * examplesPerPrint\n",
    "\n",
    "    print('dimensions: ' + str(dimensions))\n",
    "    print('total number of examples: ' + str(numfiles))\n",
    "    print('examples per print: ' + str(examplesPerPrint))\n",
    "\n",
    "    dimsX = [dimensions[0], example_win, dimensions[1]]\n",
    "    print(dimsX)\n",
    "    # save size of x_train and y_train\n",
    "    with open(path + 'dimensions_X.npy', 'wb') as f:\n",
    "        pickle.dump(dimsX, f)\n",
    "\n",
    "    with open(path + 'dimensions_Y.npy', 'wb') as f:\n",
    "        pickle.dump(num_classes, f)\n",
    "\n",
    "    with open(path + 'num_examples.npy', 'wb') as f:\n",
    "        pickle.dump(numfiles, f)\n",
    "\n",
    "    # output_print = np.reshape(output_print, (output_print.shape[0] * output_print.shape[1]))\n",
    "\n",
    "\n",
    "    if init_memmap:\n",
    "        x_file_init = np.memmap(path + 'train_data_x.memmap', dtype='float32', mode='w+', shape=((numfiles, dimensions[1])))\n",
    "        y_file_init = np.memmap(path + 'train_data_y.memmap', dtype='float32', mode='w+', shape=((numfiles, num_classes)))\n",
    "        del x_file_init\n",
    "        del y_file_init\n",
    "        print('initialized memmap files')\n",
    "    else:\n",
    "        print('init_memmap=False, skipping memmap init')\n",
    "\n",
    "    batch_idx=0\n",
    "    loaded_files_batch = 0\n",
    "    loaded_files_batch_counter = 0\n",
    "    loaded_files_total = 0\n",
    "\n",
    "    x_train = np.zeros((batch_save * examplesPerPrint, dimensions[1]))\n",
    "    print('x_train shape ' + str(x_train.shape))\n",
    "    y_train = np.zeros((batch_save * examplesPerPrint, num_classes))\n",
    "    flag = False\n",
    "\n",
    "    for key in train:\n",
    "        obj = train[key]\n",
    "\n",
    "        thisPath = path + 'audio/' + obj['note_str'] + '.wav'\n",
    "        thisClass = to_categorical(obj['pitch'], num_classes=num_classes)\n",
    "\n",
    "        instFingeprints = extract_features(thisPath, example_win, hop)\n",
    "\n",
    "        if instFingeprints.shape[0] == examplesPerPrint:\n",
    "            x_train[loaded_files_batch: loaded_files_batch + examplesPerPrint, :] = instFingeprints\n",
    "            y_train[loaded_files_batch: loaded_files_batch + examplesPerPrint, :] = np.tile(thisClass, (examplesPerPrint, 1))\n",
    "\n",
    "            print(str(loaded_files_total) + '/' + str(numfiles) + ' loaded ' + str((loaded_files_total/numfiles)*100) + '%')\n",
    "\n",
    "            # use loaded files instead of verified to avoid issues\n",
    "            if loaded_files_total >= numfiles:\n",
    "                print('last batch, saving to memmap')\n",
    "                saveMemmap(x_train, y_train, batch_idx, batch_save)\n",
    "                break\n",
    "\n",
    "            if loaded_files_batch/examplesPerPrint % batch_save == batch_save - 1:\n",
    "                print('saving to memmap')\n",
    "                saveMemmap(x_train, y_train, batch_idx, batch_save)\n",
    "                x_train = np.zeros((batch_save * examplesPerPrint, dimensions[1]))\n",
    "                print('x_train shape ' + str(x_train.shape))\n",
    "                y_train = np.zeros((batch_save * examplesPerPrint, num_classes))\n",
    "                loaded_files_batch = 0\n",
    "                batch_idx += 1\n",
    "\n",
    "            # loaded_files += 1\n",
    "            loaded_files_batch += examplesPerPrint\n",
    "            loaded_files_total += examplesPerPrint\n",
    "        else:\n",
    "            print('null file, skipping')\n",
    "            numfiles -= examplesPerPrint\n",
    "        break\n",
    "\n",
    "    print('closing file...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096 found in /Volumes/Remote_BU/Data/nsynth-train/nsynth-test/audio/\n",
      "dimensions: (9, 43776)\n",
      "total number of examples: 36864\n",
      "examples per print: 9\n",
      "[9, 256, 43776]\n",
      "init_memmap=False, skipping memmap init\n",
      "x_train shape (1152, 43776)\n",
      "0/36864 loaded 0.0%\n",
      "closing file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carl/Documents/GitHub/AudioFingerprint/fingerprint.py:26: RuntimeWarning: divide by zero encountered in log10\n",
      "  arr2D = 10 * np.log10(arr2D)\n"
     ]
    }
   ],
   "source": [
    "path = '/Volumes/Remote_BU/Data/nsynth-train/nsynth-test/'\n",
    "total_files = len(glob.glob(path + \"audio/*.wav\"))\n",
    "print(str(total_files) + ' found in ' + path + \"audio/\")\n",
    "\n",
    "parse(path, 128, total_files, 128, num_threads=1, example_win=256, hop=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
